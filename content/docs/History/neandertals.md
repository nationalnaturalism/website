---
Title: "Europeans' Ancestors"
Description: "We know very little of the period of history from 50 000 BC to the start of written history, but clear evidences show that we have been lied to about our origins as a species, and that we once existed as psychically highly advanced cultures more than 10 000 years ago."
expurged_version: false
images: ["/Images/banners/h1_lost_civs.webp"]
Requirements: ["instincto","meta"]
resources:
- url: "https://mariecachet.wordpress.com/"
  title: "Atala, by Marie Cachet"
  description: "A crucial though widely incomplete advance in understanding our origins"
  image: "none"
- url: "https://cosmictusk.com/category/younger-dryas-impact-evidence/"
- url: "https://www.ancient-wisdom.com/peruollantiatambo.htm"
  image: "/Images/history/lost-civs/ancient-wisdom-header.webp"
  description: "The objectives of ancient-wisdom are :\u000DClarifying certain 'modern myths' and 'ancient mysteries, bridging the gap between modern myth and scientific discovery and exploring if and how  ancient wisdom can be used to benefit us today."
menu:
- before
---

[migglet]: DFN "Similar to a nigglet a migglet is a black baby. However a migglet is a black baby midget, otherwise known as a black baby suffering from dwarfism."
[clines]: DFN "Measurable gradient in a single character (or biological trait) of a species across its geographical range. Clines can show smooth, continuous gradation in a character, or they may show more abrupt changes in the trait from one geographic region to the next depending on physical barriers to gene exchange."
[neoteny]: DFN "Neoteny corresponds to a state of arrested maturation, before reaching its end stage of the ancestral species. We reach maturity more slowly and maintain juvenile traits throughout our lives. In humans. Hence features often considered more <q>primitive</q> and apparent in chimpanzees, such as a slight prognathism - projection of the face forward in relation to the skull - only appear much later, and even later in women than in men."
[taurodontes]: DFN "Taurodontism describes an anatomic variation in human tooth in which the tooth's body expands to the detriment of roots. It has been used to characterize the Neanderthal condition in relation to modern humans at the paleobiological level, as well as with reference to dietary habits and paleoenvironmental contexts. It used to be considered a Neanderthal autapomorphy (derived trait). Until it was found in other apes."

National-naturalism integrates an alternative conception of human origins, but prehistory from late Paleolithic 50 000 thousands years ago from the start of agriculture ten thousands years ago must also be rewritten. We unraveled the real origin of the human species, the origin of races and the role of cooking in causing our devolution from a perfected ancestral state, with stronger senses, brain and bodies and a lifespan ten times longer. Europeans - White people in general, Nordics in particular - descend almost only from Neanderthals.

## Uncovering our ancestors

### Logical fallacies of the Out-of-Africa theory 

Biology and evolution theory textbooks, documentaries, all science, it seems, teach that the *modern* human species, the current one, descends from African apes about 6 million years ago (the number varies) from which a great number of other groups proliferated, developed and died, or merged with our remote ancestors, until they emerged victorious in the great evolutionary contest.

For the first part, we see nothing to criticize. When and where exactly we separated from bonobos, how long we wandered in Africa, is but of a mild intellectual interest at best as at the end of the day we were still **apes**, not human by any stretch of the word. Nothing political here. It gets hairy when we touch upon the emergence of men with brain size at least relative to ours, from 1200 cc onward.

But then the establishment argues that modern man left Africa around 50,000 B.C. to conquer all of Asia and Europe, mostly replacing and driving to extinction the species of men (called primitive> or archaic) already present. To then become fully modern, but strangely enough **only outside Africa**: Africans have stayed nearly identical for more than 100 000 years.

We have to visualize meak [Bushmen](/Images/biology/eugenics/physical_models/san_girls.webp) migrating all the way to Europe in the heart of the ice age, to beat in a few thousand years a native species much more robust physically and adapted to life in the North (we found some in the South of Siberia). In a nutshell, an ultra-Nordic man with a brain volume larger than any current ethny (*save for White Scandinavians*) got replaced by an African bushman whose purest modern descendants barely reach 70 IQ points.

![](/Images/racemixing_propaganda/Chasidic-Jew-raises-millions-to-provide-migrants-with-food-shoes-toiletries-says-its-a-lesson-of-the-Holocaust-Masbia-Soup-Kitchen-Alexander-Rapaport.jpg "<q>We are all Africans, children of immigrants, they are at home</q>")

![Meme we are all children of immigrants](/Images/racemixing_propaganda/decoup_is_anyone_on_earth_not_an_immigrant_live_science.webp "Oy Vey goy, shut up and give your daughters and wives to migrants!")

This myth used ad nauseam justifies all migratory invasions, the replacement of white populations by hordes of blacks and generalized racemixing. The same ideologues and media repeat night and day that races do not exist, but the white one is decidedly too big and homogeneous or downright evil. The same ones, claiming we are genetically wired to find physical differences more attractive or that mixed individuals - *enriched* racially - are healthier.

The following questions dismantle the Out-Of-Africa baseless narrative:
* How can a handful of immigrants adapted to a different climate whose skin is **still** unable to synthesize enough vitamin D without vitamin supplements survive in a _northern_ climate during a glacial ice age period? Even the Inuit, despite a raw diet very rich in vitamins and a skin less dark than that of the Blacks, traditionally suffer from deficiencies and have a short life.
* Not only would they would have to survive, but also beat the natives intrinsically adapted to a low-light environment with revolutionary features such as fair hair and blue eyes, and a robust body frame (Modern Europeans hold almost all strongman positions and strength records in the world).

![Kangz meme](/Images/memes/we_wuz_kangz_n_shieet.webp)

But somehow after an epic race war against these Übermensch, Blacks fell into an eternal slumber of the mind from which they haven't woken up. And the same thing happened in all of Asia with the neighboring Denisovan species residing there, with brains just as big, but benefiting from much softer climates (India, Thailand, all South Asia) so possibly more numerous. Still today the Negro man can not survive Northern countries without vitamin supplements and other artifices.
The official interpretation of fossils and genetics is wrong and oftentimes subversive. See the Cheddar man fiasco portraying the British WHG population as being phenotypically negroid in early-Neolithic Europe).

![Evidences Cheddar man fiasco](/Images/biology/cheddar_man_fiasco.webp)

```quote{author="Afua Hirsch, main author"}
To see Cheddar Man with his dark skin it definitely provoked quite an emotional response in me, and I think that’s the power of this. It’s one thing to know that there were black people here thousands of years ago and to know that White people weren’t always White. We know there were Africans here before there were English people here, for example, and so through that that gives you a sense of the idea that there’s this indigenous British person who is White and essentially British is a fiction, it’s a narrative that was created over time, it’s not based on scientific facts so this is another feature of that really.
```

Some backpedalling does happen now and then, but  DNA is still made to lie constantly, which is actually very easy to do when it comes to ancient (prehistoric) DNA, and studies depending on the concept of a constant molecular clock, which has been debunked.

Genetics is now used as a "definitive" argument that blue eyes are 50,000 years old[^propaganda], and that Neanderthals had a mutation on OCA2 (the gene responsible) but somehow not the same. And because no non-European blue-eyed populations existed outside Europe. Moving the goal post is the primary strategy, in genetic research, constantly postponing the need to prove the Out-Of-Africa narrative. Systematically the goal post is shifted to earlier and earlier times, which is incredibly convenient, *as DNA recovered for that time is irreparably damaged, thus unusable*. It is argued now that blue are about 50,000 years old, and that Neanderthals had a mutation on OCA2 (the gene responsible), yes, but not the same. Because no non-European blue-eyed populations existed outside Europe.

Because, there were none, because all European "Sapiens" **are** Neanderthals, which incidentally **are** described as blue or green-eyed. The molecular clock method is absolutely inadmissible for such a timespan because DNA so old is nowhere near intact enough or exploitable enough, so proving or disproving their claims this time will stay forever impossible. And *assertions that can not be proved nor could be disproved are not scientific*, and thus pointless.
 
[^propaganda]:
	```quote{cite="[Eye color -- wikipedia](https://en.wikipedia.org/wiki/Eye_color)"}
	However, more recent ancient DNA research has identified human remains much older than the Neolithic period with the OCA2 mutation for blue eyes. It is now believed that the [OCA2 allele dates back to the recent migration of modern humans out of Africa]((https://en.wikipedia.org/wiki/Eye_color#cite_note-Cberg-17)) roughly 50,000 years ago, and entered Europe from western Asia.
	```
	
### The mitochondrial Eve

The two most salient points argued by proponents of the Out-of-Africa viewpoint, are that:
- Populations in Africa has more diversity overall than all populations out of Africa, in some cases featuring more unique haplotypes than the rest of the world combined
- According to [coalescent theory](https://en.wikipedia.org/wiki/Coalescent_theory) mitochondrial DNA indicates a [MRCA](ABBR "Most Recent Common Ancestor") or [LCA](ABBR "Last Common Ancestor") in the female line as between 99 000 and 148 000 years old[](https://doi.org/10.1126/science.1237619 "Sequencing Y Chromosomes Resolves Discrepancy in Time to Common Ancestor of Males Versus Females (2013)").
- Similarly the same study estimated the last common ancestor for the Y chromosome as dating in the same last study from 120,000 and 156,000 years ago.

These wouldn't be the first male and female we would qualify as humans, but the most recent (or latest) to include in their descendants the whole of human population. These computations are obtained by running simple algorithms and formulas on respectively the whole of the mitochondrial DNA (16.5kb) for the female line and a digested Y chromosome for the male line, because these two genetic elements are inherited strictly through the parent of their respective sex with no contribution from the other parent.

What allowed this turning back of the clock, is the **molecular clock**, the first of the several wrong assumptions the mitochondrial Eve (or [MRCA](ABBR "Most Recent Common Ancestor")) make. The idea, is that sequences not subject to a selection would diverge neither faster (as under positive selection) nor slower (as under negative or purifying selection, eliminating all deviation from a strict norm) than what the slow, random accumulation of chance mutations would entail, according the average mutational rate. This only concerns non-coding sequences, *supposed* to have no effect, thus free to accumulate change.

But this reasoning is erroneous for many reasons. The concept of a molecular clock, in particular for long-lived and ubiquitous (living everywhere) species like ours so much variability in lifestyle, climate of election and mating practices, has no power to go back in time more than a few tens of millenia. [Pickford](https://doi.org/10.1007/BF02438149 "Paradise lost: Mitochondrial eve refuted (1991)") provides an in-dept theoretical debunking, which contained at least in seeds the totality of all the following points, which modern studies only confirmed ever further.

```quote{author="Pickford, M." cite="[Paradise lost: Mitochondrial eve refuted (1991)](https://doi.org/10.1007/BF02438149)"}
By adopting such a "reductionist" approach, all hypotheses based solely on neontological data [data from the living as opposed to fossiles](#) bases, however analysed, are nothing more nor less than scala naturae. **Rigorous mathematical treatments of such data bases in no way upgrade them to the status of scientific hypotheses.**
```

Confirmations only abound in later years:
- mutation rates are not constant, neither through time[](https://doi.org/10.1103%2FPhysRevE.99.022424 "Mutation rate variability as a driving force in adaptive evolution (2019)")[](https://doi.org/10.1371/journal.pbio.1000028 "Mutation Patterns in the Human Genome: More Variable Than Expected (2009)")[](https://doi.org/10.1038/s41467-022-32353-6
 "Rapid evolution of mutation rate and spectrum in response to environmental and population-genetic challenges (2022)") nor throughout the genome[](https://doi.org/10.1038/nature14173 "Differential DNA mismatch repair underlies mutation rate variation across the human genome (2015)")[](https://doi.org/10.1101/2021.01.15.426837 "Mutation Rate Variations in the Human Genome are Encoded in DNA Shape(2021)")[](htthttps://doi.org/10.1038/s41467-020-15185-0 "Nucleosome positioning stability is a modulator of germline mutation rate variation across the human genome (2020)") and [races](https://doi.org/10.1093/molbev/msz023 "Signals of Variation in Human Mutation Rate at Multiple Levels of Sequence Context (2019")
- [mtDNA](https://link.springer.com/article/10.1007/BF02099939 "Evolution of human mitochondrial DNA: Evidence for departure from a pure neutral model of populations at equilibrium (1990)") might might not be entirely neutral. Generally, determining from theory alone what sequence should or not be neutral, borders on the impossible[^proving].
	- Firstly due to unpredictable but ubiquitous effects on 3D spacial chromatine arrangement for instance, which though exerting a purifying selection for constraints on long-range nucleotide composition is not revealed through a non-synonymous vs synonymous mutation ratio.
	- Secondly [lncRNA](ABBR "long non-coding RNA") or inter-genic RNA is transcribed at various rates from the *entire* genome.
- Haploid species such mitochondria (and the Y chromosome) does indeed evolve [*uncoupled from the rest of the organism* which is diploid](www.doi.org/10.1093/molbev/msx197 "Large Variation in the Ratio of Mitochondrial to Nuclear Mutation Rate across Animals: Implications for Genetic Diversity and the Use of Mitochondrial DNA as a Molecular Marker (2017)")

[^proving]: The difficulty of proving neutrality for a sequence (which amounts to proving the absence of something that might really not be visible) does not prove it has a function, but contrary to opinions the null hypothesis shouldn't be to [disregard a priori the possibility](www.doi.org/10.3389/fgene.2015.00002/full "Non-coding RNA: what is functional and what is junk? (2015)"), and certainly not along tens to hundreds of thousands of years.

Plus, morphological (paleontology) and phylogenetic estimations are regularly found [at odds](https://doi.org/10.1186/s12862-023-02131-z "Phylogenetic congruence, conflict and consilience between molecular and morphological data (2023)") before, proving the less than perfet reliability of this method, as remains are the real deal, while estimations are just math with too [free parameters](DFN "A free parameter is a variable in a mathematical model which cannot be predicted precisely or constrained by the model and must be estimated experimentally or theoretically."). There is no surprise then, that different adjustements could produce all sorts of value for the male MRCA ranging from 50,000 and up to [250 000 years](https://doi.org/10.1016/j.tpb.2010.06.001 "Alternatives to the Wright–Fisher model: The robustness of mitochondrial Eve dating") for the female.

Another improbable factor also foreseen by Pickford, involves the effect of a variable *generation time*, meaning lifespan. The longer someone lives, the more random mutations one is susceptible to pass on to the next generation, increasing the mutation rate therefore [speeding up evolution](https://doi.org/10.1534/genetics.112.146571 "Genomic Background and Generation Time Influence Deleterious Mutation Rates in Daphnia (2013)"), though not proportionally. But too many other factors elements would render any estimation null: on one hand a generation time drastically higher should slow down the speed of selection, thus of mutations, as would superior DNA reparation mechanisms that Europeans still feature. And [targeted, programmed mutations](eugenics#lamarckism) could in theory lead to rapid adaptions leaving little mutational signature compared to the commonly postulated chance mutation model. *Regardless, such signature seems to show in Europeans' ["recent" past](https://doi.org/10.1093/molbev/msz023 "Signals of Variation in Human Mutation Rate at Multiple Levels of Sequence Context (2019)")*.
**The mitochondrial Eve is dead.**

A last argument of a genetic nature can be raised against the Out-Of-Africa narrative, one very specific to the rejection of Neandertals from our family tree, is their recovered damaged ancient mtDNA shows no similarity with modern humans whatsoever (despite x% of *purely* Neanderthal DNA being acknowledged in all non-African populations, chiefly Europeans). mtDNA concentrated the efforts historically, because its cellular abundance makes it able to survive the degradation of time, while nuclear DNA degrades so much that reconstructing the original sequence is almost impossible to reconstruct the original sequence, as mutations from time decay are entropy made manifest[](https://creation.com/neandertal-mitochondrial-genome "The Neandertal mitochondrial genome does not support evolution (2009)")[](https://www.creationresearch.org/crsq-2009-volume-45-number-4_neandertal-dna-and-modern-humans "Neandertal DNA and modern humans (2008)").

**There is simply no archaic sapiens DNA with which to compare Neandertals**, assumedly because of the low density of prehistoric <q>modern humans</q> remains, due to Africa's inhospitality for organic materials: heat and aridity promote exponential degradation, in particular of DNA which is extremely fragile, except in very special conditions such as clay ice or acidic peat bogs. Yet we only ever compare to archaic Neanderthal DNA (mitochondrial or nuclear) to modern day humans, never to equally ancient African DNA, *which does not exist*.

Truth is even if the molecular clock notion was sound, we have had no material to determine its fix-point of our clock: it's been adjusted manually to show the desired hours[^fix-point]. If we were to find a sufficient quantity and of equivalent quality of **Sapiens** mitochondrial DNA (or not) of Homo Sapiens from an equivalent period, say 140,000 years before Christ, it would appear just as different from us, alien, incompatible with any current population as time-related decay will have mutated it beyond recognition. The same applies to nuclear DNA.  

[^fix-point]:
	```quote{author="Pickford, M." cite="[Paradise lost: Mitochondrial eve refuted (1991)](https://doi.org/10.1007/BF02438149)"}
	It should be pointed out that molecular biologists have been dreadfully inconsistent about their choice of palaeontological "fix-points", the various ones chosen being incompatible with each other to a marked degree. *The only consistent part of the exercise seems to be that a "fix-point") is selected which will conform most closely with the desired running speed of the clock*.
	```

There is nothing to disprove to begin with, as no prove was ever presented.
{.important}

### Morphological continuity

So, our approach does not and can not revolve solely on DNA analyses which we deem increasingly invalid beyond the last Ice Age, as the past irreparably blurred the tracks like a sort of cosmic censorship. Instead we are driven by logic and the simple demonstrated facts of *the morphological continuity between Neanderthals, Paleolithic and Neolithic Europeans* (Asian paleontology just getting out its diapers). *On the same sites from one thousand to another we see not only the succession of one species to another from about 40,000 years ago but also their cohabitation and intermediate morphologies, tending more and more towards the modern man of today*.
{#tabun-continuity}

```quote{.aside author="Arthur J. Jelinek" cite="[The Tabun Cave and Paleolithic Man in the Levant](https://www.jstor.org/stable/1689660)"}
An analysis of these materials strongly supports a continuity in cultural development at this site from about 130,000 to 50,000 years ago and suggests that a continuous biological evolution from Neanderthal to anatomically modem Homo sapiens took place in the southern Levant.
```

While for the few remains we have, the sub-Saharan African skull (pure type without mixture) has essentially not changed since 200,000. Erectus did originate in Africa and groups left it around 1.5 million years it earned the label of <q>chronospecies</q> as for a long time we find a morphological continuity between the different groups with no clear boundaries, so that local denominations change willy-nilly and the usual definition of a species through interfertility, might or might not apply anymore, with gradual incompatibilities both in time and space between the first almost ape-like Erectus and the latest stage relatively big-brained specimens.

![Three racial types](/Images/biology/eugenics/three-racial-types.webp)

```quote
Homo Ergaster (robust erectus stage) is attested in Africa between about 1.9 and 1 million years before the present. At the beginning of its existence, it cohabited with Homo Rudolfensis, Homo Habilis, and Paranthropus Boistei in East Africa, and with Homo Gautengensis and Paranthropus Robustus in southern Africa.
Its endocrian volume varies from 750 to 1,050 cm³, with a trend towards the increase over time. The sexual dimorphism of this species would be smaller than at Homo Habilis. Homo Ergaster remains very archaic of facies, with an absent nose and a very prognathic jaw.
```

The description resembles many current Africans. In all likelihood multiple branches of Erectus around the world, including the Eurasian ones, evolved along a common trend of cerebral increase (at different rates though) with very slow but continuous by gene exchanges along genetic [clines] ?

The oldest Homo Ergaster would be the ancestor of homo erectus in Asia. It is likely that it is also the ancestor of  in Europe. It may seem hard to believe populations of twice 800,000 years divergence can still interbred (Pygmies and Norwegians to take the purest examples), but in reality it is not the only case in nature. Time is less important than the mutation rate, and amount of selected, significant mutations vs neutral ones vs drift, and some adaptations matter more than others when it comes to breeding, resulting in various degrees of anatomical, genetic, behavior incompatibilities etc. All of this, one cannot estimate from time passing only.

The likes of the Tautavel Man (Europe, 455 000 years) with very mature features somewhat closer to Erectus with 1166 cm³, is hard to place. We don't really need to think that far, as various theories based on analyzes are routinely invalidated: paleontology competes with social psychology for the medal of the softest science. However a large consensus is established regards to Tautavel as the first safe element of the line of Neandertals.

So it seems likely, to conclude, that at least 500 000 years ago, due to environmental changes (the onset of the last, still ongoing glacial cycle) started differentiating with a common trend towards an increase in brain size - as getting dumber is never an advantage.
Notice how the modern European skull meant to have appeared all around the world at the same time around -40 000 has nothing in common with neither modern nor Ancient African skulls, whereas the Asiatic and European skulls look a lot like a *juvenile* Neandertals skull (which does not show yet prominent brow-ridges).

archaic homo sapiens:
{.center}
- ![qafzeh_9_skull_from_israel](/Images/biology/cranes_africains_ancestrales/qafzeh_9_skull_from_israel.webp)
- ![skhul_V](/Images/biology/cranes_africains_ancestrales/skhul_5.webp)
{.center}
The <q>modern</q> African:
{.center}
- ![africain-1.webp (655×443)](/Images/biology/cranes_africains_ancestrales/africain_moderne_1.webp)
- ![af.webp (461×365)](/Images/biology/cranes_africains_ancestrales/africain_moderne_2.webp)
{.center}

The Nordic European skull currently peak at 1500 and average at 1440 cm³. The Neandertals or his Asian cousin had a ceiling of 1700. Here is a rather striking comparison:

![sdfsdg](/Images/biology/neandertals/comparaisons_skull_sapiens_neanderthal.webp)

For those who might be shocked by these large arches, it is important to understand that really ugly eyebrow arches are not that common in Neandertals, perhaps 3 or 4 fossils in all. At an equivalent level of maturity (in proportion to their total lifespan), they retained more childlike and gentler features than we do, without sacrificing strength and robustness as aesthetics and beauty, both inner and outer, were major elements of their instincts, as they are of ours.  children looked like... children. A lot more so, for the same age. We used to stay young for **decades**.

- ![neandertal_red_hair](/Images/biology/neandertals/neandertal_red_hair.webp "Imagination")
- ![red_hair](/Images/biology/eugenics/physical_models/red-hair.webp "**Reality**")
{.center}

![reconstruction](/Images/biology/neandertals/most_recent_reconstruction.webp "**Most recent Neanderthal reconstruction**")
{cite="[Una nuova approxssimazione facciale per l'Uromo de la Chapelle-aux-Saints 1 (2023)](10.13140/RG.2.2.33164.08326)"}

![](/Images/biology/neandertals/hyperrealistic_neanderthals.webp "Why does he look like my grandpa not shaving for a year ? Seriously,\
how deep can cognitive dissonance run ?")

Several details have often been exaggerated or even flatly falsified in some cases (and the fossils tampered with), such as this forward projection to give it a simian look and the absence of a chin. For two hundred years, reconstructions did not stop making him look primitive and brutal. From the start centuries ago the first archaeologists being Christian priests destroyed many relics and finds, for fear of turning the official biblical story upside down. How can we place such men, similar but better in every way, than current humanity saved by *Jesus*? Could they date back to before the flood ?

But the most recent and accurate reconstructions have now dropped the act, and finally show the truth of our origins, even though no one seems to have noticed. If figures need be cast, assuming a rough proportionality (certainly wrong), a Neandertals in the third of his life, which would correspond to 30 years in our country.

Now, what we preserve by lying and hiding artifacts, is the culture the victors of WW2 cemented, with its antiracism and egalitariasm. If the world were to know that the White Man is Neanderthal itself and has degenerated from a semi-divine anterior race, Nazis would be proved right over night in the eyes of millions if not tens of millions, and rightly so.

### Multi-regional origin

The explanation is a multi-regional origin of the man, or more exactly of the three root races: White, Black (including Congoides and Capoides/Bushmen/San), Asian/Mongoloid. The genetic aspect of the argument will be touched upon below.

This classification as old as it is, is easy to apply, and recent (dependable, unlike when dealing with degraded 30,000 years remains) [population genetics validate it](https://thuletide.wordpress.com/2020/06/29/a-race-by-race-breakdown-of-human-genetic-diversity-illustrated-guide-for-novices/ "A Race-By-Race Breakdown of Human Genetic Diversity: Illustrated Guide for Novices -- Thuletide (2022)").

It is easier to refer to craniometric measurements than to genetics, because such visible traits depend on a large number of genes, difficult to isolate as well as to quantify... while their expression is observed in the mirror. Moreover, skulls are much better preserved than DNA and mutations (natural or due to degradation) considerably distort genetic analyses, while physical characteristics, often produced by natural selection, can remain the same through time. This fact will be useful to us later.

![images 4 primitive skulls](/Images/biology/comparison_of_skull_features_of_homo_naledi_and_other_early_human_species.webp "for a rather accurate comparison:")

![Neandertals-sapiens comparison](/Images/biology/neandertals/neanderthal_sapiens_comparison.webp)

There is no question that humans do originate from Africa but much earlier, leaving the continent along coastal lines. Then several groups splitted giving the homo antecessor, from which the Homo Sapiens or Negro evolved, and homo heidelbergensis, probable common ancestor of Neandertals man and Denisova man (presumed main ancestor of the mongoloid populations of which the purest instance would be Southeast Asians, that is to say the Chinese, Koreans and Tibetans). Other branches of homo erectus appeared and disappeared, like these two dwarf species (no more than 1.50 m) with a reduced brain, Homo floresiensis and Homo Luzonensis.

Insular dwarfism aside, the tendency for all other species/races, has been a continuous process of encephalization, a larger brain size. But some more than others. Thus the species in Asia and Europe have developed a brain reaching a ceiling of 1700 cm³.

Given that brains use a lot of energy and civilization didn't exist, those huge blobs of grey matter must have been put to use and incredibly intensively: the adaptive pressure, wherever it came from, must have been strong enough to sustain that nigh continuous increase for a good 300 000 years. That meant their intelligence was from significantly higher than ours to genius-level on a species-scale, maxing out everything they could get from their organ.

An alternative hypothesis states that because eye sizes have been shown to be adaptations to cold (to the preponderance of snow in the Arctic environment, to be precise), and brain size positively correlate to eye sizes, thus the bigger eye sockets (not biggers *eyes* mind you) of Neanderthals would explain their bigger brains without implying a higher intelligence.

But this demonstrably **wrong**.
This correlation means nothing. Logically, at most we should assume propotionality, meaning that twice the visual information should require at most twice the processing power, hence at most twice the brain volume in the visual cortex, the part dedicated to visual information processing.
And we see quickly that this correlation is not proportional at all:
> The results showed that the biggest brains, averaging 1,484 millilitres, were from Scandinavia, while the smallest brains, around 1,200 millilitres, came from Micronesia. Average eye socket size was 27 millilitres in Scandinavia and 22 millilitres in Micronesia.

The conclusion would be that Nordic Europeans got 300 additional cc of brain to process a mere 23% increase in visual information, while the visual cortex is but [20% of the brain](https://www.spinozacentre.nl/dumoulin/PDFs/Wandell-Encyclopedia-2009.pdf "Visual Cortex in Humans -- Encyclopedia of Neuroscience (2009)"). Scandinavian eye size being just 23% bigger than Micronesians', if we suppose proportionality, this difference should only explain 56 more cubic centimeters, not *5 times more*.

Samewise, another argument relates to body size. Among related species differences in brain size have been correlated to difference in body mass: the more mass, the more information to process. Leading to the false assumption that relative (to the body) brain size matters more for intelligence than absolute size, although [evidences are slim](https://arstechnica.com/science/2018/08/the-evolutionary-mystery-of-gigantic-human-brains/ "The evolutionary mystery of gigantic human brains (2018)") and scientific opinions mellowed out this last decade: It is believed now that most of the brain does not scale in size with body mass in any straightforward way, as most bodily processes occur identically for a 1.4m tall [migglet], or a 1.9 Icelandese strongman.

Beside this would assume Neanderthals had a much higher body mass, which is demonstrably [wrong](.#same_bmi). Their BMI was no different from ours. Micronesians reach a measly 157.05 cm and while medieval Vikings reached an average of 173cm (not really tall it seems !) Neanderthals on the other hand were on the shorter side as far as Europeans are concerned: 1.68m. Yet their brain was so big. That means it was bigger in absolute terms **and** relative to their body mass.

Simply their significantly higher [encephalic quotient](DFN "The encephalization quotient (EQ) is a measure of relative brain size and is often used to convey how small or large a species brain is compared to that of other species of similar body size.") demonstrates a higher level of evolution.
{.important}

And so it makes no sense that the Negro, judging from his current technological and cultural inferiority and significantly lower average IQ throughout the continent even despite decades of integration in the West (as verified in interracial adoption contexts), could ever have beaten Neanderthals in their home turf, considering the later were to modern Europeans what we are to Africans.

Neandertals went nowhere, did not die, but degenerated into present Europeans.
{.important}

Northernmost populations the purest, as their environment reflect Ice age conditions which used to be prevalent. Nords being uniquely adapted, little to no non-European admixture occurred until fairly recently.

## *We are Neandertals.*

### Cooking and auto­domestication

A lot of robustness was lost but it was gradual, and the typical Neandertal skull shape is regularly found in some individuals (in the form of the "hemi-bump" among other things), to the point that assuming a simple mixture between 3 to 5% as one can read, makes absolute no sense. The supraorbital torus (browridges), fair skin eyes and hairs and the highest cranial capacity *in the world* can be found [in Scandinavia according to studies](www.doi.org/10.1098/rsbl.2011.0570 "Latitudinal variation in light levels drives human visual system size (2011)"). It is no racist posturing than to say the Nordic race has the biggest brains, but mere facts.

Hence the Nordic race, adapted to the arctic conditions of life, is the Neandertal man, who did not undergo any substantial mixing, as indicated by the conservation of many recessive traits. The change is explained nearly entirely by the degeneration we brought on us by ourselves.

[Mrs. Marie Cachet](https://mariecachet.wordpress.com/2012/09/26/2-glaciations-and-migration-hybridization-and-survival-en/) concludes that we are 99% Neanderthals, and that the degeneration into progressively "modern" humains has been caused by first hybridization with Africans, and secondly auto­domestication in the context of the Neolithic revolution and agriculture.
Her arguments for the survival of Neanderthals in current Europeans, in particular Nordics, are absolutely unassailable. We resumed them above, but she provides extensive archeological and anatomical evidences in her website, so we warmly advise to browse it in its entirety. The second part however---explaining the degeneration---is bullocks.

A time of extreme cold alleguedly pushed European populations, reduced to very small numbers, to the brink of extinction and forced them to move to the Middle East and more amenable climate. We supposedly met Africans there and interbred, and this very slight mixture minimal was supposedly enough to curse our species, kickstarting a radical downward spiral in reducing the women's pelvises' size, with only mothers giving birth to babies of gradually smaller brain surviving delivery, finally reaching the point of today.

Gracility (loss of robustness) must have developped with the sedentarization and civilization, with a result similar to what we observe in cows, dogs and pigs. The incoherent mixtures in the same site of characteristics and diseases that we begin to observe in the bones from 40,000 kg would be explained by the mixtures, the first <q>half-breeds</q>, half-negroid half-Neandertal, disparate and dysfunctional sets of genetic and anatomical inheritances, just as with current half-breeds.

```quote{.aside}
Wolves are the largest of the canines, and they come in a variety of sizes. The gray wolf, which is the most common species, typically weighs between 80-100 pounds but can get as big as 175 pounds. They measure about 30 inches tall at the shoulder. Wolves are consistently stronger, larger, more resourceful and more intelligent than dogs of any breed. With bigger brains as well. This phenomena is observed uniformly in all domesticated animals, including cockerels.
```

![wolf-size](/Images/biology/wolf-size-humans.webp)
{cite="[An arctic wolf can measure up to 1.80m and a gray wolf, more than 1.90m](https://misfitanimals.com/wolves/wolf-size-comparison/)"}

Domestication also involves the selection of infantile traits, such as barking in dogs, which disappears in wolves as adults. The whole psychology and the attitude of dependence of the dog towards man, shows a perpetual regression to the state of a puppy, an attitude selected for the ease with which one can train and control a cub rather than an adult wolf, and this is true for any species. With the infantile character comes an [underdevelopment of the brain](https://link.springer.com/chapter/10.1007/978-3-642-70877-0_13 "Mammalian Domestication and its Effect on Brain Structure and Behavior (1988)").

But the theory of hybridization as the mother of all ills, which sounds like an improvable deus ex-machina, a kind of cosmic catastrophe whose unfolding steps seem incredibly gratuitous and specious.

First off, despite enough admixture to cause such a monstrous effect, not just Scandinavia but still 2000 year ago most of Europe still had blond hair and blue eyes, and in many people strong robust traits. All **recessive traits** that should very much betray any significant admixture, but they don't.

Then the most salient weakness of that idea, is that if mixing had been the cause, the first intermediate forms should show considerably more admixture than later forms and not less, then as the hybrids back-cross into the wider Neanderthal population (as necessary to reduce the admixture to less than one percent as she claims), forms should normalize in aspect, and be closer to the Neanderthal type. The reason is simple: mixing is not a continuous, but a step-wise process, with the first generation necessarily starting at 50% (metis on steroids), then half that, then half that, etc.
But as we saw, the **opposite** is true: we see in some sites a very continuous morphological weakening in bones' robustness, skull size etc, instead of a drastic shift to a gracile type. The real explanation Marie Cachet missed, which is the key to everything, is *cooking and the onslaught of pathogenic and mutagenic denatured molecules*.

### Neoteny and the shortening of lifespan {#neoteny_theory}

Forgoing the environment and evolutionary pressures that shaped us, for living in artificial conditions far remote from any form of natural selection, moreover arranged to facilitate an exgtremely lazy life compared to that a hunter-gatherer lifestyle (in the Ice Age !), allowed mutations of any order to proliferate and multiply when life in the wild would have permitted their carriers to survive. As a result the genetic or epigenetic patrimony is ever more damaged, incurring a gradual loss of highly evolved traits less and less required or even incompatible with life in civilization, such as a superior intelligence or anti-social tendencies.

Mental automatisms known as feedback that automatically accompany cooking cause an imbalance of higher mind functions and the essential divide with the extrasensory world. This is the real reason behind the tendency for civilization which took root since. Christians would call this the Fall:

```quote{cite="Bible, Genesis"}
And to Adam He said:
<q>Because you have listened to the voice of your wife and have eaten from the tree of which I commanded you not to eat, cursed is the ground because of you; through toil you will eat of it all the days of your life. Both thorns and thistles will yield for you, and you will eat the plants of the field.</q>
```

The cases of wild children scattered in today's literature show that it is in fact not very difficult to live in nature, even the highly degraded nature found at the end of the Middle Ages. This indicates that have a super strong god-like body was never really necessary for Neandertals to survive in nature... nor were psychic powers either. The only explanation for our evolution is Lamarckian heredity: through consciousness which a population would impulse its own evolution in reaction to the environment, encoding adaptations and especially instincts in a certain direction, modifying moral and aesthetic sensibilities and changing our criteria for love partners: instincts and intelligence become their own evolutionary engines.

This is probably how human species starting from some threshold in brain size (say, 1000 cubic centimeters perhaps) have continued to develop despite being effectively immune to predation through their tools and team work. One had to be familiar with raw food to know the effects of cooking on consciousness and the brain at large, and even fathom what its suden adoption would imply for evolution, it being the key to explain the nature of the anatomical change we underwent.

![](/Images/biology/ecology/rosarot-axolotl.jpg "The axolotl, a large tadpole breeding in the larval stage")

Our species in its present state, especially the white and Asian race, has what can be called a tendency to neoteny. This analogy may have more truth than at first glance. From our own point of view we enjoy an exceptionally long juvenile period (between weaning around 6 years and adulthood), compared to the faster fertile apes... Dietary and racial factors are prevalent: Europeans and Asians grow much longer (even after puberty) and *rich* diets lead to more [abundant frequent and early menstruation](instincto#impossible-fertility), [faster growth](instincto#adolescent-growth-spurt)... and an early menopause. So much so that a proportion of girls start bleeding at 9 now, and **getting pregnant at 10**.

Dentist Dr. Jack Cuozzo, from a literals Christian perspective, has found the key to the mystery. Studying the fossils as a dentist, he revealed many anomalies not congruent with the interpretations of paleontologists, especially regard to the growth rate and supposed age of the fossils. It has also revealed false reconstructions that no one with a basic knowledge of anatomy could have done in good conscience... revealed alterations and damage done to the fossils themselves with the obvious aim of forcing fossils to submit to their desires and to depict Neandertals as inferior. The fanatics of the theory of evolution, who like all fanatics react with violence and denial to any evidence of errors of their doctrines. These are serious accusations, but widely documented.

But the reddest herrings **concerned the age of the fossils**: Dental and bone morphology indicate either a strong precocity and speed of growth even superior to that of apes... a much, much longer growth period than ours.
We could give the example of a morphologically very young crane, but the jaw was well developed (indicating weaning), and the milk teeth showed signs of extensive wear which did not correspond to the estimated age. Problem is tooth wear has been shown a constant *independent of lifestyle*, and (over whole populations) reflecting *only the passing of time*[^teeth_buried]. Their primary teeth were much more robust than ours, more than our definitive ([taurodontes]) teeth[^teeth]). In all cases, wear is attributed to unknown lifestyle agents yet undiscovered in current populations, however primitive. In his words: **"Age or ape !"**

We used to estimate age by the number of deciduous and permanent teeth by assuming the eruption schedule of modern populations for these prehistoric men and ignoring signs of dental wear or cranial development. In the 1980s people still wondered if Neandertals could even talk!
Cuozzo's second discovery was the typical Neandertal morphology not being a simian trait we would have lost from the apes that prehistoric men preserved, nor the result of a very rapid growth, but the result of a multi-century growth instead. In other words: Protracted growth or unbelievably accelerated maturation in the same amount of time as us.

Many people ignore it but we continue to grow after puberty: though  in a slowed down fashion (in absence of disease or deficiency) bone mineralization continues, in particular on long bones (limbs) and the face, causing an elongation of the face. We are all born with a very small face in relation to the head, a ratio increasing with age from some level of retrognathism (pushed backwards) in babies and fetuses to the flat face of maturity, to a forward extension on older people. As he explains:
> What Happens to the Craniofacial Structure of Humans Who Live Past a hundred years", if one mathematically projected the bone profile one would get if one could continue to live past the canonical ages of 120 years, considering contemporary growth rates one would find back Neandertal-like features. The Neandertals were the old people of the Bible just after the Fall, before and just after the Flood, when mankind began to live shorter and shorter lives.

However, the theory of bone thickening such as the suborbital bulges (brow ridges) as a structural compensation of the mechanical constraints exerted by jaw muscles over time is wrong, even though they are indeed rarely found today and thus the progressive diminution in fossiles would match well a corresponding shrinking of the life time as the Bible and numerous other texts (Egyptian, Summerian, Greeks). The reasons are:
- I said before, some Europeans still show absolutely Neanderthal-like strong facal features now and then, in particular in Scandinavia, despite a normal (for our standards) ageing. And the biggest torus by far... *is found in Australian Aborigineses*.
- The torus bony composition varies greatly from person to person, some being filled, some [hollow or spongy](http://www.jstor.org/stable/2742733 "The Supraorbital Torus: \"A Most Remarkable Peculiarity\" [and Comments and Replies] (1985)"), thus naturally incapable to act as a dissipatory mechanism, in particular in Neanderthals, getting <q>almost paper-thin</q>.
- This trait is common in nearly *all* early homini*n*s, from pre-humans to chimpanzees, all animals eating primarily *fruits*, and for the longest time our lifestyle has never required huge a biting force, arguably less so than in some human nearly carnivorous modern populations with very hard chewing requirements, but no remarkable torus. Samewise, With instinctonutrition we develop a stronger bite force by habit, with the current skull proving perfectly adequate.
- Studies with models and animals alike[^no_correlation] showed *less* stress during ontogeny (development), and no difference with hollow or filled toruses. Proving that its development serves no mechanical function and has been genetically programmed for at least 46 million years (divergence between Old World and New World primates).

In general this trait never faded from archaic hominins to Neanderthals to modern people, so much that our lifespan increased, but *prominently the juvenal phase of our life*, so that an extreme torus (or other signs of maturity) become statistically rarer and *only exhibited by the very oldest people*.

We are not prevented from becoming full adults: we just don't live old enough while ageing much too fast.
In effect, *to Neandertals we are all Progeria victims*.
{.important}

It is likely that the vast majority of mutations in humans, in a natural context, are intentional and endogenous, not chaotic. It took a very important source of chaotic mutations, which was cooking, to break the genetic correction mechanisms that allowed us to live so long. In itself, longevity is not a novelty in nature, the axolotl can live up to 150 years and as for the Greenland shark, [between 260 and 410 years](https://fr.wikipedia.org/wiki/Requin_du_Groenland#Mythes_et_r%C3%A9alit%C3%A9s).

But human beings have a much faster metabolism than theirs, of course, but other animals are known to strictly speaking <q>not age at all</q>, i.e. not losing any ability with age. This is rather common with crustaceans like the lobster, which grows (sometimes to impressive sizes) until it dies by predators or fellow creatures (cannibalism), or if it's lucky by surviving until a moult when its carapace has become too thick for it to discard, and he dies. The strong natural selection and intraspecific competition regulates their population. Closer still is the dwarf mole rat, which I have already mentioned.

So the idea of living a thousand years, a biological quasi-immortality, would merely be the next evolutionary step.

### What we lost

#### Neandertal diet

For the longest time, and still now, the prevailing opinion is that Neandertals were mostly predators, or at least consumed, in some part of the year, an overwhelming quantity of meat. Giving credence to (normal, not us) paleodiet proponents which very often eat lots and lots and lots of it, looking down or fruits or god forbid, insects or sea shells despite a predictable intimacy with the [sea](https://doi.org/10.1371%2Fjournal.pone.0186684 "External auditory exostoses and hearing loss in the Shanidar 1 Neandertal (2017)")[](https://doi.org/10.1371/journal.pone.0186684 "Midden or Molehill: The Role of Coastal Adaptations in Human Evolution and Dispersal (2019)"). 
This resulted from the use of the isotopic analysis method[](https://www.doi.org/10.1073/pnas.120178997 "Neanderthal diet at Vindija and Neanderthal predation: The evidence from stable isotopes (2000)")[](https://www.doi.org/10.1073/pnas.2109315119 "A Neandertal dietary conundrum: Insights provided by tooth enamel Zn isotopes from Gabasa, Spain (2017)")[](https://doi.org/10.1073/pnas.1814087116 "Exceptionally high δ15N values in collagen single amino acids confirm Neandertals as high-trophic level carnivores (2019)") to determine diet, is to determine the proportion of certain isotopes, from zinc strontium and nitrogen mainly. Some isotopes (atoms with the same number of protons as their namesake, but more or less neutrons) are heavier, thus in statistically in certain processes take less part (even though to a very small degree) in molecular exchanges associated with bone turnover or respiration. Some sources of those atoms also presnt distinct profiles, allowing one to speculate about the main sources of proteins in an animal's diet, although it must be stated, very broadly. Then as the animal die and get buried, the exchange with the environment naturally ceases, and the proportion of *radioactive* isotopes start to fall off, as they decay and are no longer replaced. This rate is then analyzed using more or less precise formulas depending on conditions, age etc. But they do give a qualitative estimation, when compared with living animals and their place in the food chain.
As it stands, opinions are nearly unanimous that Neandertals were the greatest predators to ever exist, with rates of meat consumption absolutely over the roof, higher than even hyenas, which are obligate, 100% carnivores !

But these analyses are worthless for several reasons.
- Reason 1: Many sources of proteins are rarely if ever considered, and their differential apports in isotopes even less so, assuming we know them. *Insects* are never considered despite being a key component of many human populations world-wide, and of all primates. If fish is considered, *sea shells are not*. Recently (2017) *[rotten meat](www.doi.org10.4207/PA.2017.ART105 "Putrid Meat and Fish in the Eurasian Middle and Upper Paleolithic: Are We Missing a Key Part of Neanderthal and Modern Human Diet (2017)")* has been found to display a higher, bacteria-enriched <sup>15</sup>N/<sup>14</sup>N (the latter being the most comon one) profile than fresh meat. Since rotten meat is by far preferred (if not only) way to consume meat world-wide in all populations still eating raw, that must force a reconsideration of the traditional mammouth-slaying, über-alpha-giga toundra master image we have been fed into children' head for decades if not a century already. 
- More crucially, the other reason behind these rates, that no one could have foreseen, is that isotopes profiles do not freeze only at the moment of death. Their proportions depend on the bone turnover rate of the body, meaning the speed at which new bones is created/destroyed.
This has never entered into consideration as by and large no land animal or mammal lives more than a few decades, at most a century, than the others. And the intraspecies variation in life is slight to null.
*No one knows what would happen to these rates if we could suddenly extend an animal life ten times its ordinary size.*

The answer is, bones (and moreso, *teeth*) lasting centuries to a millenia instead of at most a single century, would accumulates the heavier isotopes to the point the ratio would appear exceed the most predatory animals, despite the actual proportion of meat in the diet being negligeable, no higher than shown in chimpanzees (less than 3%). And there is no reason whatsoever, they would deviate from it, certainly not a lack of fruits and nuts.

Hence not only Neanertals featured a balanced, typical ape diet (plant remains abound) but these studies provide an unexpected and incontrovertible element of proof to the extended lifespan hypothesis.
{.important}

*And there are no evidences of cooking among Neandertals so far*.
Dental calculus in a number of individuals of El-Sidron (47,300-50,600 BP) showed trace presence of aromatic substances produced during heating in a number of food sources[](www.doi.org/10.1007/s00114-012-0942-0 "Neanderthal Medics? Evidence for Food, Cooking, and Medicinal Plants Entrapped in Dental Calculus (2012)"). Yet the researchers unambiguously state that there is no definite evidence and all <q>the relative abundances of these combustion markers are entirely consistent with those found in wood smoke</q> (unsurprising for a cave-dwelling **caveman**) and that <q>there were no diagnostic protein markers or steroidal compounds indicative of meat ingestion</q>. Yet through the article they can not let go of the marked preference for the cooking hypothesis. One reason is the persistence for describing "starchy food" remains in the dental calculus, which they identify as probable seeds, hence why their minds must be aching to see an analogue to our *cereals*.
But let us not forget that the definition of "starchy food" including seeds, sweat potatoes and beans. No ties to cooking nor impediment to eat them raw as we do. But the impediment lies in the reseachers' obtuse mind: They are incapable of eating these food raw, or if they do, to appreciate them... *But those concerns did not stop a number of subsequent articles to take cooking as a now established fact.* Several other times, charred food remains were found on site, and that is consistent with *simply dumping one's (abundant) food remains in the fire to feed it.*

#### Physical strength

![diagram_fiber](/Images/biology/eugenics/physical_models/apes_chimpanzee_bonobo/diagram_fiber_experiment_chimp.webp)

The markings on bones (musculo-tendinous attachments) akin to that of apes indicate approximately the level of stress muscles exerted throughout the individual's life, on the the corresponding bones, relative to our own bones. And in the case of Neandertals those As we saw, prior analysis draw the inescapable conclusions that they were not merely earlier stage of our evolution but a **higher** one, a perfected Nordic race like Elves are often described, so simply imagining a rugged mountain of muscles deprived of the slightest grace (as in most modern reconstitution) doesn't fit. Instead, we must consider a people **stronger pound for pound**, like apes. According to studies the marks of their bones indicate their muscles developped the same strength as chimpanzees. Indeed those figures are even higher than what recent studies found for apes.

![chimp_naked2](/Images/biology/eugenics/physical_models/apes_chimpanzee_bonobo/chimp_naked.webp)

Humans share with **sloths** the palm of having the most relative amount of slow-twitch type I fibers. Yet while bearing less muscles for their size compared to other mammals and obviously not requiring much explosive power, **sloth arms are still twice as strong as ours for the same mass**[](https://slothconservation.org/think-stronger-sloth/ "Do you think you are stronger than a sloth? -- Sloth Conservation Foundation")[](https://www.doi.org/10.1152/japplphysiol.01118.2017 "Cheap labor: myosin fiber type expression and enzyme activity in the forelimb musculature of sloths (Pilosa: Xenarthra) (2018)"). Hence among different species drawingconclusions from fiber composition about strength doesn't work, nor does the opposite (claiming Neanderthals had explosive strength but not endurance).

![predator](/Images/spirituality/mythology/modern/neanderthal_predator.webp "Not this:")

![guts](/Images/biology/eugenics/physical_models/berserk-guts.webp "**But this !**")

As always efforts are undertaken to minimize the human anomaly, here arguing either that our weakness either comes from our brain leaving no sugar for the muscles or that we traded explosivity for endurance. However it is patently wrong that chimpanzees tire easily, on the opposite their arms strain for a considerable time while moving from branch to branch, sustaining a body weight for extended periods. We descend from Neanderthals which, that we know for certain due to studies and artifacts found, that they did not lack in fine motor control in any way. Yet possessed ape-like strength, as estimated from bones.
We may have developped smaller fibers allowing for selective activation and finer movements, but to deduce a loss of explosivity makes no sense, as it would imply the impossibility of activating more smaller units at once. *Cortical inhibition*, in the sense of limiting ourselves for no reason, can not be an evolutionary feature as most of time our muscle mass would be dead weight to carry: if evolution needed more strength, we would have discarded muscle mass (a fortiori our *fat*). We should be able to access 100% of our strength on command.

Cortical inhibition is explained *an unconscious mechanism stopping ourselves from using 100% of our strength and rip our muscles to shreds*, sinews and tendons asunder, while the better protein composition of animals doesn't mind. This plus the higher mechanical advantage their longer muscular attachments provided both Neanderthals too and apes, would explain at least the two times increase in overall strength, and probably more. 

Next, Neanderthals were shorter than us. A 1.73m French, would tower over 99% of our ancestors, who averaged between 164 and 168 for men and resp. 152 to 156 cm for women. Undoubtedly short for today, but actually unremarkable for pre-industrial Europeans, or even still right before World War 2. The mass of an individual (and so, its *shape*) is difficult to estimate with any precision from a skeleton, [triply so from a fossile](https://doi.org/10.1016/j.jhevol.2015.04.007 "Neandertal energetics: Uncertainty in body mass estimation limits comparisons with Homo sapiens (2015)"). As per current (varying) estimations Neanderthals' BMI was 27, so *overweight* according to current standards. Firt off, let us keep in mind that the BMI (kg per square meters) means precisely shit regards to shape, as it does not differenciate weight from muscles or from **fat**.

[Thicker bones](www.doi:10.1016/j.jhevol.2010.09.009 "Femoral curvature in Neanderthals and modern humans: A 3D geometric morphometric analysis (2011)") and muscular strength twice ours too can not be explained entirely by lifestyle requirements (essentially training), setting Neanrthals apart from modern *and* early humans (Cro-magnons): It just indicates a strength partially lost to degeneration. This was caused by cooking damaging our DNA thanks to an unprecedented amount of denatured mutagenic and genotoxic molecules etc. Hence the loss of complexity, brain size, women's pelvises, joints... everything got dumbed down.

They had more or less the same physique as a wild chimpanzee, as would any wild animal: a maxed-up yet practical body. Masses are estimated through the size of long bones and skulls, guessing at the mass behind according to modern ratio, or in some cases extrapolating the strength necessary to leave behind the [visible strain marks bones exhibit](https://doi.org/10.1016/j.jhevol.2010.09.009).

But in both cases the estimation is of course extremely indirect. Representations never take into account the important fact (yet acknoweldged here and there) that ancient humains (all species included) must have had the same efficiency as chimpanzees, around twice our strength pound for pound. This leads to mucle mass estimation to be *grossly overestimated*, as the same skeleton carried around or power applied through an articulation, **our ancestors only needed half the mass we currently need**. Hence their real BMI must have been closer to Bruce Lee, which weighted at his prime 65.9 kg of pure, alluring muscles for a height of 173cm, giving a BMI of no more than BMI of 22.5.

These imaginary weights have been used to reduce their calculated encephalization quotient (brain to body mass ratio), in order to relativize (read: cope with) the excessive intelligence those humongus braincases indicate.

In reality, aesthetics in a sane person indicates that fat percentage for men should stay between 8 and 10% (see this gallery with trained men). 

- ![](/Images/biology/bad_bmi.webp "Official representation")
- ![](/Images/biology/good_BMI.webp "Athletic man")
{.center}

While the shape of bones hints at the stress exerted on them, our point is that if true, the more than likely hypothesis of a higher ape-like **efficiency** allowed Neanderthals to keep a peak-human look, Captain America-like look. super-human look maybe, but **human** nonetheless, not gorilla-like. At least for some some muscle groups, the proportion and thus physique to deduce, doesn't require much imagination since they still exist in some rare populations, the Aleuts, who obviously, beside good-looking thicker arms, look fine.

Men and women were equally much more sturdy than us, so much so that usually we cannot differenciate men and women from skulls alone. Their women would have folded the biggest of our MMA fighters, for half their weight[^female].
From musculo-tendinous attachments on their bones (and their **curvature** under great tension, something we don't see today) we are forced to consider physiques hardly common today, strong women capable to arm-strong current halterophiles, and men throwing them around like rag dolls. Such fit bodies, we hardly ever see today in men, let alone women.

![Strong_woman](/Images/biology/eugenics/physical_models/caliesthenics/caliesthenics_female.webp)

![strong_woman3](/Images/biology/eugenics/physical_models/caliesthenics/caliesthenics_female3.webp)

The complicated question of what physique is the most natural for women won't be tackled here, but everything from our decades of instincto experiences to pure aesthetic considerations, points at our girls being **much too fat and physically pathetic**. Like for any animal, women should be on average more agile than men of the same size, lighter (so should be their skeletal mass), and for the same age, usually smaller. However, the same mass should warrant the same power, even though distributed differently. There is simply no point in excess fat for survival value, no ape is a bear, **we do not hibernate nor need to stock fat during winter**, instead we use our brain to find food or stockpile it in prior auspicious seasons.

Many animals store or hoard food, by instinct or conscious forecasting, it doesn't matter. But to assume muh big brained humans/aryans/whatever didn't use to, is an insult to our allegued intelligence. Monkeys and chimpanzees have been seen hoarding fruits, perhaps intuiting they risked missing the occasion to come by again to eat more of them. **Squirrels** with a brain the size of walnut singlehandedly disprove the need for agriculture (or in the case of Varg Vikernes' cult, either abundant subcsutaneous fat or tons of meat) to endure food-deprived winters without half your offspring dying.

![squirrel_walnuts](/Images/images_article_instincto/squirel_wallnuts_42_gallions.webp)
{cite="[A squirrel his thousands of walnuts under the hood of a man's truck. It wasn't the first time](https://www.washingtonpost.com/nation/2021/09/30/squirrel-truck-fargo-bill-fischer/)"}

![acorn_woodpeckers](/Images/images_article_instincto/acorn_woodpeckers.webp "That fellow, the acorn woodpecker, [could also teach us lessons in foresight:](https://youtu.be/cZkAP-CQlhA)")

Ultimately, the best practice to find the perfect **adult** female physique from a functional point of view (best male physique too), seems to be **calisthenics**. While our sense of aesthetics can be fickle or subject to conditioning, evolution favors this kind of efficient body. Later European Nordid types, such as Hallstatt Nordids and Trønders, presenting traits in comparison highly neotenic (such as a pronunced high forehead, reduced browridge), should not be interpreted as signs of the arrival of a new species, or worse, God forbid, the unholy union of frail Nigger blood and brutish-looking Neanderthals.

Instead those new types, coexisting with the Cro-Magnoids Coon labelled <q>Upper paleolithic survivors</q> presenting much closer characteristics, with more robust-looking skulls, proportionally smaller foreheads and longer faces (but larger as well relative to the head), reflects what ageing does while our lifetime became too short for classical Neanderthal traits to develop fully at their initial speed. That neoteny in and of itself is no sign of degeneracy, quite the opposite: Neanderthals matured much more slowly and at any given age maintained traits from earlier stages of maturity. Typically children were born **lookling like overgrown foetus**. In terms of lifespan, we are born, breed and die as kids, almost neonates. The comparison with the axolotl is much more than an humoristic analogy.

Conversely, those  while those that do reach maturity demonstrate undeniable Neanderthal blood, it might also indicate accelerated *ageing*. Looking old and mature when most hope to live exactly a mere tenth of what our genetic is still mostly programmed for, *is not good a sign at all*.

We must consider, that nearly Neanderthals we found with accentuated mature traits were not adults but extremely old people, which to cite the late Dr Cuozzo, <q>would look very funny</q>. This would explain a few health defects typical of [extremely outworn skeletons](https://doi.org/10.1016/j.jhevol.2017.12.004 "La Ferrassie 1: New perspectives on a “classic” Neandertal"), despite otherwise not looking that old to our scientists, rarely more than 50.
White people should not aspire to look like that, anymore than a child should desire growing too fast, way too fast. On the contrary, the longer we look young while growing strong (otherwise it's confusing slow maturation with **under**-maturation) *the slower we age and in better diet condition the longer we could hope to live*. There is no good or bad Nordic types as long as no obvious admixture witih Mediterranneans (read: Semites) or Asians can be proved. If anything, the classic Nordid look seems more natural as we could assume the bulk of the population at any given time, was morphologically speaking either young or adult but not old, hence would look exactly like us, just stronger.

## Cooking and the Fall from heaven

### Summary of our evolution

Around one million and a half years ago local groups of Homo Erectus (whose cranial box averaged 775 cc), the first truly human stage of evolutionary line, in facial features as well as cranial capacity with an average of 1,000 cc, varying from 546 to 1,251 cc, *the extremum nearly identical to current African average 1,268*. He is alleguedly the first to leave Africa along coastial regions, and populated Eurasia (meeting or not earlier iterations of [hominins](https://www.ancient-origins.net/human-origins-science/mankind-arose-europe-not-africa-021987 "7.2 million-Year-Old Pre-Human Fossil A Challenge to Out of Africa? (2020)")) where they started diverging into the ancestors of the White and East-Asian races. For around 700 000 years, evolution followed everywhere a common trend of encephalization, with populations falling behind sooner or later disappeared, either absorbed by more successful ones or dying out.

Between 300 and 200 000 years ago brain sizes reached the 1000 cubic centimeters threshold with the emergence of the classic Neanderthal type, and Homo Sapiens in Africa. Presumably was reached too, our current level of intelligence, given that some very capable, like Anatole France, function well in our society. Then Africans started diverging sensibly in their evolutionary path, their brain size stagnating when ours soared.

- ![](/Images/biology/prognathism_chimp2.webp)
- ![](/Images/biology/chimps_elongated_faces2.webp)
{.center .aside}

Before that, we see that facial traits were even more robust on average, more prognathes and accentued. It makes sense that our intelligence increased, our lifespan must have slowly extended past that of chimpanzees as well, reaching at most 150 years, the theoretical maximum of today with medicine and proper food, in the best conditions. Before the classical Neanderthal traits emerged, European hominins had more accentued traits, a flatter forehead and [on average thicker brow ridge than later Pleistocene humans](https://nutcrackerman.com/2017/04/20/the-supraorbital-torus-in-hominins/).

This facial development could match a chimpanzee (or bonobo) basis---though flattened and elongated to fit human proportions---growing past its final state. Then something happened, which kickstarted a rapid (compared to previous rates) increase of brain size. A *psychic awakening* must have occured with us, that did not take in with Africans, explaining our rate of evolution way beyond anything natural selection could have motivated, with maturation decreased proportionally while our life expectancy soared.

### Biblical insights

At the beginning of the cooking process, with degeneration significantly undermining our life force and natural regenerative abilities, the damage must have been light, perhaps imperceptible, like the patriarchs like Noah who lived after the Fall but before the Flood, and *merely* drank wine.

![Curve of Biblical patriarchs' age](/Images/images_article_instincto/curve_patriarchs.jpg)

There are more people cured from hard drugs, than those weaned from cooking. According to a drug addict, giving up cooking is even more difficult than for heroin. It is not improbable if we imagine a people both uninformed and hospitable, that cooking swept the world almost instantaneously as far as fossil records are concerned, so on the scale of a few thousand years.

With animals as well as human beings, we observe a difference between the cooked state and the natural raw state, proportional to the size of the brain... to the capacity for introspection and metacognition. Your intellect has to be able to control and regulate your deranged impulses. Animals fed cooked food without the support of recipes (such as dog food) specially designed to reduce the immediate effect on health, for the most part, will eat whatever they find and die quite quickly of disease, violence, rather spectacularly.

Although human behavior is greatly altered, animal behavior  are even more so, due to their impulsivity, due to a lack of a metacognition and self-control. It would make sense that people with a bigger brain and more advanced physiology, without our frustrations and still much closer to energy, would be able to buffer the effect of an initially slight alteration to their diet ?

Thus people would have had memories from centuries of mental stability, and might have enjoyed yet more centuries after starting cooking. Then the next generations would suffer more, and more, and more, and more. As their sexual instincts went unbounded cooked groups ended up outbreeding the rest.

Since the old age of patriarchs (in whichever era they really lived) appears confirmed by science, we should start to consider the Bible (along with a few other texts) not as figments of the imagination, but as sometimes literal sometimes symbolic retelling of the prehistory of Man, condensing the sequence of events from the First Age to the Flood and modern times.

Since we know the precise dates of death and ages of every patriarch, we can compute the number of years from the Fall to the Flood, to 1656, over [ten generations](https://answersingenesis.org/bible-timeline/timeline-for-the-flood/). We see in the list of patriarchs that from Adam to Noah, everyone had a lifespan of roughly 1000 years, with no discernible degradation in vitality. But let us first start at the beginning, with Genesis.

From 2:9 to 2:17, God explicitely allows Adam to eats from all trees from the Garden, including the free from the Tree of Life, with the express exception of the tree of the knowledge of good and evil and *only* this one. Moreover in ℣17 God warns of the consequence, namely that by eating this fruit Adam <q>would certainly certainly die</q>. However the form used is <q>תָּמֽוּת׃</q>, which is the simple imperfect, *not an imperative or jussive* thus does not express an order or a wish from God, nor a threat, but the [simple description of what is to come in the indefinite future](https://uhg.readthedocs.io/en/latest/verb_imperfect.html "Verb Imperfect, Hebrew Grammar").

Then, when after the temptation of the serpent (which is a symbol ambiguous between chaos and rebirth), Eve sees that the fruit (intellect), as the serpent told her, was also desirable for gaining wisdom. That wasn't a lie, as indeed intelligence is a form of wisdom, but of which kind ? Then immediately, bashfulness appears in paradise (3:6), followed by the very explicit exposition of the fallen human condition now alloted to the couple, and the expulsion from Eden.

This knowledge of good and evil</q>, representing intellectual intelligence, which is part of Nature (human nature in particular) but God (destiny). Intelligence is part of divine beings themselves, as claimed by the serpent in book 3:4 *but confirmed by God/angels in verset 22*, so that we know the serpent was not lying...

Before the Fall, men were mostly vegetarians, as are apes, their amount of animal proteins being nearly negligeable, never more than 5%. Then God created the woman (actually for the second time). As 2:24 implies (<q>and they become *one flesh*</q>), *sexuality was meant to exist before the Fall*, but a different kind, without guilt, *without desire* and without the typical heterosexual fixation of females on males, which is listed by God to Eve in 3:16 (<q>Your desire will be for your husband</q> as a consequence of her new fallen condition.

Lest we conclude the God and angels from Genesis are actually evil and mean, unwilling to share their divinity (yet unable to put that damn tree anywhere else, or just immediately cast out Man after its creation if that was the plan all along), God intended intelligence to develop only after transcendendal wisdom had been aquired, implying a certain level of extrasensory maturity to wield the intellectual power with responsability.

We must therefore assume the eating of that fruit and fall in a degraded form of intellect (and thus, of sexuality) refers to an accident, a fundamental change causing our dissociation from God's grace.

The consequence of that Fall, are as follow:
- Fertility goes out of control (<q>I will multiply your sorrow and conception</q>) and the whole process of childbearing from conception to delivery becomes painful (alluding not just to labor, as is often mistranslated)
- Not relying on fruit trees anymore but having to toil to produce cereals[^cereals], while mysteriously the soil is cursed to loose its fertility
- Hyper-intellectualization leads to the loss of sexual innocence, thus the disconnection from energy and gradual loss of capability for transcendence
- Women are condemned to a purely reproductive sexuality.

We undeniably see here the avatars of **cooking**.
God didn't change change Adam's body much if at all, since for ten generations him and his descent lived just as long as one another, not is it said that he was immortal in heaven. On the contrary, it's logical to assume he was meant to become immortal at some point after eating from the right tree, whenever he wanted, and that his newly-found mortality is not caused by an exterior God but by Man's estrangement from Nature, as a result from his own action. Eating cereals just doesn't happen without cooking, for this probably not refered to sweet corn or raw sprouts.

Before the fall, men were not fated to die, implying that ageing did not happen (or nowhere near as quickly as today) and that at least true apotheosis (the **impossibility** to die) was well in reach within one's lifetime:
```quote{cite="[Was Adam Created Mortal or Immortal? Getting Beyond the Labels ?](https://henrycenter.tiu.edu/2018/05/was-adam-created-mortal-or-immortal-getting-beyond-the-labels/)" author="Joshua van Ee" #eternal}
This understanding of Genesis 2–3 fits well with Augustine’s three categories for human mortality before the fall, after the fall, and after consummation: **possible not to die, not possible not to die, and not possible to die** (City of God, XXII.30). Adam before the fall was not doomed to die. Yet, Adam before the fall also did not have the consummated/glorified body, *the fullness of the living forever tied to the tree of life*. Thus, Adam before the fall was still awaiting *confirmation in eternal life*. Adam, if he had obeyed, would have attained to the consummated/glorified body without having to pass through death.
```
But while the Fall announced the inevitability of death, for a time God still interacted on a daily basis with men, and transcendence could still be achieved by a select few. He gave us (instead of striking us dead from disobeying Him and natural laws in general, as he should have), *profitting from long lives to repent on our sin and perhaps change our ways*. Only much later, right before the Flood, did God decide that enough was enough, not only did mankind not understood any lesson in this reprieve.

The unfolding of our history as it occured, was no more than a mere accident, a dramatic and unforeseen byproduct of three things:
- The pathological psychology created by dietary poisoning
- Our god-given gift of intelligence and freewill, the extension of the capacity of all intelligent animals for self-control, the delaying and amending the realization of instinctive impulses
- Our hands, which allowed for technology.

The issue was, that past a certain threshold, we humans have been relying on the extrasensory to control the capacity of our intellect which aided by our hands, had now the capacity to alter our environment to a higher extent than any other species so far in history. Other animals have had either the intelligence to use fire, anatomical skill for manipulation even at a large scale (social insects razing whole forests), or the environment to produce a lasting culture---otherwise diet alterations can not cumulate to the individual--- but never all of these factors combined.

So what started as accidental poisoning, became permanent due to our intelligence now unshackled, unguided and left unchecked by the extrasensory, which does not work within those hyperexcited nervous conditions. Psychological damages stacked up through cultures and then genetics, making the species fall deeper and deeper into depravation. This led to the complete disconnection of our intellect from the metapsychic program, to such an extent that no amount of instinctive backlash (Excalibur drive) or visionary warning, could reach enough clarity to pierce through the species-wide fog of mental disease and reset diet and mental equilibrium to their natural state.

[^teeth]:
	> If the roots were longer, the pulp could not retreat as far because the dividing point in the root structure would be closer to the body. Since it is low-down in the lower jaw or high-up in the upper jaw, the pulp can retreat quite far as reparative dentin builds up. This means the taurodont tooth will last longer than the normal "cynodont" tooth which, by the way, means "dog-like".
	> Hillson said taurodonts were also found in modern man but it was a rare variant. **Pinborg found it in less than 0.1% of modern humans**. Stringer thought the shape of these roots is produced by "a delayed turning-in of the base of the roots" during their formation. He also thought this feature was related to the extreme wear endured by Neanderthal teeth, because teeth with undivided roots will maintain a whole chewing surface even when worn past the crown into the unseparated root area.
[^abundant]:
	> In Niort, the marriageable age of boys cannot be set before eighteen; The marriageable age of girls is generally sixteen. In the high plains, as well as in Gâtine, the marriageable age is delayed by two years for each sex: it can only be set at eighteen years for girls and twenty years for boys. In the marshy part, on the contrary, especially among the somewhat wealthy class, we could set the marriageable age of girls at fourteen years. Development is not earlier there among boys whose marriageable age can only be set at eighteen years, as well as in the city: the difference is therefore four years between the puberty of girls and that of boys. boys.

[^strong]: 	```quote{cite="[How Strong were the Neandertals? Leverage and Muscularity at the Shoulder and Elbow in Mousterian (2006)](https://www.academia.edu/1439962/How_strong_were_the_Neandertals_Leverage_and_muscularity_at_the_shoulder_and_elbow_in_Mousterian_foragers)"}
	*Assuming no difference in muscle composition* (i.e, the proportions of type I and type II fibers: 72) or architecture, the rough estimates above suggest that Neandertals had somewhere between **1.3 to 2.0 times greater upper body strength than seen in the average modern human from an industrialized, agricultural economy**.

	we can estimate the out-force of this muscle at 101.0 N and 69.7 N (or 22.6 lbs and 15.6 lbs) in male and females, respectively. In elbow extension, then, the Neandertals appear to have been some 79% to 96% stronger than modern human comparators.
	```
[^female]: 	```quote{cite="[The shanidar neanderthals (1983)](https://annas-archive.org/md5/7482183d48e22cd358f979779e84fdf6), p.43"}
	Whereas it is possible to estimate reliably the sex of about 90% of recent human skeletal material using a variety of indicators (Krogman 1962), it is uncertain how many of the traits used for sexing modern human skeletal material can be applied to fossil hominids (Genovés 1969). **Early attempts to assign sex to incomplete fossil remains led to a disproportionate number of specimens being called male** (Genovés 1954; Weiss 1972). This probably resulted from paleontologists' using the general level of robusticity of the skull as a sexual indicator, and because early hominids are more robust than recent humans, *most were referred to as male*.
	Not only are Neandertal and other early hominid crania generally more robust than those of recent humans, **but most of the qualitative characteristics traditionally used to discriminate male and female crania** are inapplicable.
	```
[^cereals]: ```quote{cite="[Lilith in the Bible and Mythology](https://www.biblicalarchaeology.org/daily/biblical-topics/hebrew-bible/lilith-in-the-bible-and-mythology/)"}
	Like the <q>shrub of the field</q>, the Hebrew expression translated as <q>plant of the field</q>, *esev hassadhe*, is very rare in Scripture. Indeed, it appears only twice—in Genesis 2:5 and 3:18. The key to understanding the nature of this plant is found in Genesis 3:17, 18 (NIV), *where we are told that the 'esev hassadhe is the very plant that Adam will have to eat as a result of his Fall!* <q>and you will eat the plants of the field</q>. These plants are not the fruit-bearing trees that God provided for man's food on day three. *Rather, they are the plants humans will have to cultivate after the Fall*. 
	```
[^no_correlation]:
	```quote{cite="[Masticatory Loading and Bone Adaptation in the Supraorbital Torus of Developing Macaques (2009)](www.doi.org/0.1002/ajpa.20972)"}
	SED [strain energy density](#) values were found to be low in the supraorbital torus region throughout ontogeny, while they were consistently high in the zygomatic arch and infraorbital region. Thus, if the supraorbital torus arises to resist masticatory loads, it is either already adapted in each of our subadult models so that we do not observe high SED or a lower site-specific bone deposition threshold must apply.
	```
	```quote{cite="[Supraorbital morphology and social dynamics in human evolution (2018)](https://doi.org/10.1038/s41559-018-0528-0)"}
	Once the reconstruction was complete (model 1), the frontal sinuses were infilled to allow later excavation of this region to produce variant morphologies. Analysis of the impact of infilling the sinus in model 1 showed that the surface strains over the browridge and elsewhere in the cranium did not differ significantly between the models with hollow and filled frontal sinuses.
	```
[^teeth_buried]:
	```quote{cite="Buried Alive"}
	Also, the tooth in front of it doesn’t have the corresponding back side or distal side worn down to the same extent. This means that the primary or baby tooth, called the second primary molar, was the tooth that did most of the rubbing against the front surface of this permanent molar. This primary tooth is usually lost at or around 11 years of age. Some children hold on to them a year or so longer.In my 30 years of practice as an orthodontist I have seen thousands of these primary molars [*milk teeth*](#) and I can’t remember one that caused this much wear on the front surface of a permanent molar.

	He noticed the excessive amount of wear on the first primary (baby) molars as compared to the second primary (baby) molars. This suggested a more protracted time between the eruption of these teeth than found in today’s children. Today’s children have their first and second primary molars erupt about 9 months to one year apart. These two teeth in the Engis child look like they were separated by a much longer time frame than that. **This is what protracted eruption means: more years between tooth eruption**.

	The question that remains is, what happens when there is extensive wear of all the biting surfaces of the teeth and the face doesn’t stay the same length but, instead, gets longer or increases in facial height? This happened in Neanderthals. Does this represent overcompensation? Would it mean a higher rate of the adult passive tooth eruption process with very rapid bone build-up on the lower border of the lower jaw in the average Neanderthal life span of 45 years, 36 or 40 years? *Or could it be the regular process of compensation at a normal or slower rate of passive eruption with an average or slower rate of bone build-up on this border over a much longer lifetime?* We will discuss this later.
	```
